{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70203,"databundleVersionId":8068726,"sourceType":"competition"},{"sourceId":11898572,"sourceType":"datasetVersion","datasetId":7479500}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"There are some duplicate audio files in the train data, so we discard them. Data in train_audio is also filtered with Google-bird-vocalization-classifier: if the classifier’s max prediction doesn’t match with the primary label, the chunk is dropped (maybe there is no bird sound or it has a bad quality). If the classifier’s max prediction matches with the secondary label, we replace the primary label with the secondary label. Moreover, if the file has secondary labels, then we take the primary label with 0.5, and the remaining 0.5 is evenly distributed among the secondary labels. We also add pseudo labels obtained with Google classifier to the resulting labels with a coefficient of 0.05. The soundscapes are labeled with an ensemble of Google classifier, and our best models trained only with train_audio. Finally, if the sound is too short, we use cyclic padding.\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Drop Duplicates: Using metadata and duration of the audio.\n\nDiscard Bad Chunks: Use GBVC, generate labels and match them with primary or secondary labels, discard if no match.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport pathlib\nfrom glob import glob\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nimport pandas as pd\n\nimport torchaudio\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tensorflow_hub as hub\nimport tensorflow as tf","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata = pd.read_csv(\"/kaggle/input/birdclef-2024/train_metadata.csv\")\n\nAUDIO_PATH = Path('/kaggle/input/birdclef-2024/train_audio')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:55:47.484662Z","iopub.execute_input":"2025-05-21T16:55:47.485052Z","iopub.status.idle":"2025-05-21T16:55:47.613100Z","shell.execute_reply.started":"2025-05-21T16:55:47.485026Z","shell.execute_reply":"2025-05-21T16:55:47.612135Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __len__(self):\n        return len(metadata)\n    def __getitem__(self, i):\n        filename = metadata.filename[i]\n        audio = torchaudio.load(AUDIO_PATH / filename)\n        duration  = len(audio[0][0])/audio[1]\n        return duration, filename\n        \ndataloader = DataLoader(AudioDataset(), batch_size=1, num_workers=os.cpu_count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:55.226959Z","iopub.execute_input":"2025-05-21T16:45:55.227322Z","iopub.status.idle":"2025-05-21T16:45:55.234705Z","shell.execute_reply.started":"2025-05-21T16:45:55.227292Z","shell.execute_reply":"2025-05-21T16:45:55.233609Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"duration_df = {\n    \"filename\": [],\n    \"duration\": []\n}\nwith tf.device('/gpu:0'):\n    for duration, filename in tqdm(dataloader):\n        duration_df['filename'].append(filename)\n        duration_df['duration'].append(float(duration.numpy()[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:59:08.890112Z","iopub.execute_input":"2025-05-21T16:59:08.890488Z","iopub.status.idle":"2025-05-21T17:11:00.306992Z","shell.execute_reply.started":"2025-05-21T16:59:08.890458Z","shell.execute_reply":"2025-05-21T17:11:00.305614Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 24459/24459 [11:51<00:00, 34.38it/s] \n","output_type":"stream"}],"execution_count":143},{"cell_type":"code","source":"duration_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"https://www.kaggle.com/code/robbynevels/bc24-google-bird-model-embeddings-predict-score?scriptVersionId=172204890&cellId=4","metadata":{}},{"cell_type":"code","source":"import librosa\n\ndef get_duration_librosa(file_path):\n   audio_data, sample_rate = librosa.load(file_path)\n   duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n   return duration\n\ndef get_filename(path):\n    path_dirs = path.split(os.path.sep)\n    filename = \"/\".join(path_dirs[-2:])\n    return filename","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}